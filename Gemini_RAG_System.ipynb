{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51298152",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q -U google-generativeai faiss-cpu openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c770c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "from openai import OpenAI\n",
    "import numpy as np\n",
    "import os\n",
    "import numpy as np\n",
    "import faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39d7bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "API_KEY = \"YOUR API KEY\"\n",
    "genai.configure(api_key=API_KEY) \n",
    "\n",
    "# Sample Data\n",
    "sample_text = \"\"\"\n",
    "Artificial Intelligence (AI) is the simulation of human intelligence processes by machines, especially computer systems. \n",
    "These processes include learning (the acquisition of information and rules for using the information), reasoning (using rules to reach approximate or definite conclusions) and self-correction.\n",
    "Particular applications of AI include expert systems, speech recognition and machine vision.\n",
    "\n",
    "AI research has been highly successful in developing effective techniques for solving a wide range of problems, from game playing to medical diagnosis.\n",
    "The history of AI began in antiquity, with myths, stories and rumors of artificial beings endowed with intelligence or consciousness by master craftsmen.\n",
    "The seeds of modern AI were planted by classical philosophers who attempted to describe the process of human thinking as the mechanical manipulation of symbols.\n",
    "This work culminated in the invention of the programmable digital computer in the 1940s, a machine based on the abstract essence of mathematical reasoning.\n",
    "This device and the ideas behind it inspired a handful of scientists to begin seriously discussing the possibility of building an electronic brain.\n",
    "\n",
    "The field of AI research was founded at a workshop held on the campus of Dartmouth College during the summer of 1956.\n",
    "Those who attended would become the leaders of AI research for decades. Many of them predicted that a machine as intelligent as a human being would exist in no more than a generation and they were given millions of dollars to make this vision come true.\n",
    "Eventually it became obvious that they had grossly underestimated the difficulty of the project.\n",
    "In 1973, in response to the criticism of Sir James Lighthill and ongoing pressure from congress, the U.S. and British Governments stopped funding undirected research into artificial intelligence, and the difficult years that followed would later be known as an 'AI winter'.\n",
    "\n",
    "Seven years later, a visionary initiative by the Japanese Government inspired governments and industry to provide AI with billions of dollars, but by the late 80s the investors became disillusioned and withdrew funding again.\n",
    "This cycle of boom and bust, of 'AI springs' and 'AI winters', continues to haunt the field.\n",
    "Nevertheless, AI has seen a resurgence in recent years due to advances in machine learning, big data, and computational power.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c8b086",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Text chunking function\n",
    "def chunk_text(text, chunk_size=300):\n",
    "    chunks = []\n",
    "    for i in range(0, len(text), chunk_size):\n",
    "        chunks.append(text[i:i + chunk_size])\n",
    "    return chunks\n",
    "\n",
    "# Split the sample text into chunks\n",
    "chunks = chunk_text(sample_text)\n",
    "print(f\"Number of chunks: {len(chunks)}\")\n",
    "print(\"Sample chunk:\", chunks[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14fa7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embeddings\n",
    "embedding_model = \"models/embedding-001\"\n",
    "\n",
    "def get_embedding(text):\n",
    "    result = genai.embed_content(\n",
    "        model=embedding_model,\n",
    "        content=text,\n",
    "        task_type=\"retrieval_document\"\n",
    "    )\n",
    "    return result['embedding']\n",
    "\n",
    "# Generate embeddings for each chunk\n",
    "embeddings = [get_embedding(chunk) for chunk in chunks]\n",
    "print(f\"Embedding dimension: {len(embeddings[0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87c771c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vector torage using FAISS\n",
    "dimension = len(embeddings[0])\n",
    "index = faiss.IndexFlatL2(dimension)  # L2 distance index\n",
    "index.add(np.array(embeddings).astype('float32'))\n",
    "print(f\"Number of vectors in index: {index.ntotal}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9efd9504",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Context retrieval function\n",
    "def retrieve_context(query, k=3):\n",
    "    query_emb = np.array([get_embedding(query)]).astype('float32')\n",
    "    distances, indices = index.search(query_emb, k)\n",
    "    retrieved_chunks = [chunks[idx] for idx in indices[0]]\n",
    "    return retrieved_chunks\n",
    "\n",
    "# Example query\n",
    "query = \"When was the field of AI founded?\"\n",
    "contexts = retrieve_context(query)\n",
    "print(\"Retrieved contexts:\")\n",
    "for ctx in contexts:\n",
    "    print(ctx[:100] + \"...\")\n",
    "\n",
    "# generation\n",
    "generative_model = genai.GenerativeModel('gemini-1.5-flash')  \n",
    "\n",
    "def generate_answer(query, contexts):\n",
    "    context_str = \"\\n\\n\".join(contexts)\n",
    "    prompt = f\"\"\"\n",
    "Answer the question based on the following context. If the context doesn't contain the answer, say \"I don't know\".\n",
    "\n",
    "Context:\n",
    "{context_str}\n",
    "\n",
    "Question: {query}\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "    response = generative_model.generate_content(prompt)\n",
    "    return response.text\n",
    "\n",
    "# Example answer generation\n",
    "answer = generate_answer(query, contexts)\n",
    "print(\"Generated Answer:\")\n",
    "print(answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46323498",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag_query(query, k=3):\n",
    "    contexts = retrieve_context(query, k)\n",
    "    answer = generate_answer(query, contexts)\n",
    "    return answer\n",
    "\n",
    "# Test with another query\n",
    "new_query = \"What is AI winter?\"\n",
    "print(\"Query:\", new_query)\n",
    "print(\"Answer:\", rag_query(new_query))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
